# ğŸ“Š Component Prediction Pipeline

## ğŸ¯ Purpose

Clean and predict REAL components for Airbnb pricing:
- **TfL Transport** (daily journeys in millions) - REAL data
- **Tourism** (quarterly visitor counts in thousands) - REAL data
- **Weather** (temperature, precipitation, quality) - REAL data
- **UK Holidays** (bank holidays, major events) - REAL data

**Note**: No synthetic `foot_traffic_score` - only real, observable components.

---

## ğŸš€ Quick Start

### â­ Recommended: Run Complete Pipeline
```r
# Navigate to the project folder first, then run:
source("00_run_all.R")
```

**This will**:
1. Clean all 4 data sources
2. Merge into daily framework
3. Predict future components (TfL, Tourism, Weather)
4. Create `foot_traffic_daily.csv` with REAL components only

---

### Alternative: Run Step by Step

```r
# Step 1: Clean individual sources
source("01a_clean_tfl.R")       # TfL transport
source("01b_clean_tourism.R")   # Tourism  
source("01c_clean_weather.R")   # Weather
source("01d_clean_holidays.R")  # Holidays

# Step 2: Merge to daily framework
source("02_merge_to_daily.R")
```

---

## ğŸ“ Structure

```
foot_traffic_prediction/
â”œâ”€â”€ 00_run_cleaning.R           â† Run all scripts
â”œâ”€â”€ 01a_clean_tfl.R            â† TfL cleaning
â”œâ”€â”€ 01b_clean_tourism.R        â† Tourism cleaning
â”œâ”€â”€ 01c_clean_weather.R        â† Weather cleaning
â”œâ”€â”€ 01d_clean_holidays.R       â† Holidays cleaning
â”‚
â””â”€â”€ foot_traffic_data/
    â”œâ”€â”€ raw/                    â† Your downloaded data
    â”‚   â”œâ”€â”€ tfl/tfl-journeys-type.csv
    â”‚   â”œâ”€â”€ tourism/international-visitors-london-raw.csv
    â”‚   â”œâ”€â”€ weather/london_weather.csv
    â”‚   â””â”€â”€ events/uk_holidays.json
    â”‚
    â””â”€â”€ cleaned/                â† Output (4 files only)
        â”œâ”€â”€ tfl_monthly.csv
        â”œâ”€â”€ tourism_quarterly.csv
        â”œâ”€â”€ weather_monthly.csv
        â””â”€â”€ holidays_monthly.csv
```

---

## ğŸ“Š Output Files

### Individual Source Files (4 files):

| Script | Output File | Granularity | Content |
|--------|-------------|-------------|---------|
| `01a_clean_tfl.R` | `tfl_monthly.csv` | Monthly | Transport journeys |
| `01b_clean_tourism.R` | `tourism_quarterly.csv` | Quarterly | Visitor statistics |
| `01c_clean_weather.R` | `weather_daily.csv` | **Daily** | Weather data |
| `01d_clean_holidays.R` | `holidays_daily.csv` | **Daily** | Holiday flags |

### â­ Main Output (1 file):

| Script | Output File | Content |
|--------|-------------|---------|
| `02_merge_to_daily.R` | **`foot_traffic_daily.csv`** | **Daily framework with all data merged** |

**This is the file you'll use for modeling!** 

Contains:
- Every day from 2019-2024 (~2,000 rows)
- **TfL daily journeys** (millions) - REAL data
- **Tourism quarterly visits** (thousands) - REAL data
- **Weather** (temperature, precipitation, quality) - REAL data
- **Holidays** (flags and weights) - REAL data
- **Normalized indices** (0-1) for each component (for convenience)

---

## ğŸ“ˆ Data Coverage

| Dataset | Time Period | Records |
|---------|-------------|---------|
| **TfL** | 2010-2024 | ~170 months |
| **Tourism** | 2002-2020 | ~75 quarters |
| **Weather** | 2019-2024 | ~60 months |
| **Holidays** | 2024-2027 | ~48 months |

---

## âš™ï¸ Requirements

```r
install.packages(c("tidyverse", "data.table", "lubridate", "jsonlite"))
```

---

## âœ… Success Check

After running, verify:
```r
list.files("foot_traffic_data/cleaned/")
# Should show 5 files:
# [1] "foot_traffic_daily.csv"      â† MAIN OUTPUT
# [2] "holidays_daily.csv"
# [3] "tfl_monthly.csv"
# [4] "tourism_quarterly.csv"  
# [5] "weather_daily.csv"

# Check the main output
daily_data <- fread("foot_traffic_data/cleaned/foot_traffic_daily.csv")
nrow(daily_data)  # Should be ~2,000 days
head(daily_data)
```

---

## ğŸš€ Next Steps

After cleaning:
1. **Inspect the daily data**:
   ```r
   library(data.table)
   ft_daily <- fread("foot_traffic_data/cleaned/foot_traffic_daily.csv")
   summary(ft_daily)
   ```

2. **Visualize component patterns**:
   ```r
   library(ggplot2)
   ggplot(ft_daily, aes(x=as.Date(date), y=tfl_daily_avg_m)) +
     geom_line() + labs(title="TfL Daily Journeys")
   ```

3. **Use components for Airbnb pricing**:
   - Access component predictions via `get_components()` function
   - Create your own pricing adjustment logic based on REAL components
   - No synthetic scores - only observable data

---

## ğŸ“ Notes

### Data Granularity Strategy:
- **Daily data**: Weather, Holidays (exact values each day)
- **Monthly average**: TfL transport (each day gets its month's average)
- **Quarterly average**: Tourism (each day gets its quarter's average)
- **Normalized indices**: Each component has its own 0-1 index (for convenience)

### Why Mixed Granularity?
âœ… Captures daily variations (weather, weekends, holidays)  
âœ… Preserves monthly/seasonal trends (transport, tourism)  
âœ… Perfect for daily Airbnb pricing predictions  
âœ… Avoids false precision from interpolation

### Data Coverage:
- **Weather**: 2019-2024 (complete daily coverage) âœ…
- **TfL**: 2010-2024 (monthly averages applied to days) âœ…
- **Tourism**: 2002-2019 (quarterly averages, ~72 quarters) âš ï¸
- **Holidays**: 2012-2027 (complete UK bank holidays) âœ…

---

**Last Updated**: November 2024  
**Status**: âœ… Production Ready

